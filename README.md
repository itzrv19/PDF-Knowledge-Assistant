# ğŸ“˜ PDF Knowledge Assistant

A chat-based **Retrieval-Augmented Generation (RAG)** application that allows users to ask
questions directly from PDF documents and receive **accurate, document-grounded answers**
with **page-level citations** and **relevance scoring**.

This project is designed with a strong focus on **trust, transparency, and usability**,
ensuring that answers are generated strictly from the uploaded document â€” without
hallucinations or external knowledge.

---

## ğŸš€ Features

- ğŸ“„ Upload any PDF and interact with its content
- ğŸ’¬ Chat-style conversational interface
- ğŸ“Œ Page-level citations for each answer
- ğŸ¯ Relevance scoring with visual indicators
- ğŸ›¡ï¸ Strictly document-grounded answers (no hallucinations)
- ğŸ¨ Clean, professional, and intuitive UI
- ğŸ” Secure handling of API keys (no hardcoding)

---
---

## ğŸŒ Live Demo

ğŸ”— **Live Application**

```text
https://your-app-name.streamlit.app
```

---

## ğŸ§  How It Works

1. **PDF Loading**  
   The uploaded PDF is read page-by-page while preserving page numbers.

2. **Text Chunking**  
   Each page is split into meaningful, sentence-based chunks while keeping metadata
   such as the page number.

3. **Embedding Generation**  
   Each chunk is converted into a semantic vector using a Sentence Transformer model.

4. **Vector Storage**  
   All embeddings are stored in a ChromaDB vector database along with their metadata.

5. **Semantic Retrieval**  
   When a question is asked, the most relevant chunks are retrieved using vector
   similarity search.

6. **Answer Generation**  
   A language model generates answers **strictly from the retrieved chunks**.
   If the answer is not present in the document, the assistant responds accordingly.

7. **Explainability**  
   The UI displays:
   - Page numbers for source content
   - Relevance scores for each retrieved chunk
   - Optional visibility into the supporting text

---

## ğŸ§© Architecture Overview

```text
PDF Document
     â†“
Page-wise Parsing
     â†“
Sentence Chunking
     â†“
Vector Embeddings
     â†“
ChromaDB Vector Store
     â†“
Semantic Retrieval
     â†“
LLM Answer Generation
     â†“
Chat UI with Citations & Scores



---

## ğŸ› ï¸ Tech Stack

- **Frontend / UI**: Streamlit
- **Vector Database**: ChromaDB
- **Embeddings**: Sentence Transformers (`all-MiniLM-L6-v2`)
- **LLM Inference**: Hugging Face Inference API
- **PDF Processing**: PyMuPDF
- **Language**: Python

---

## ğŸ” Security & Best Practices

- API keys are **never hardcoded**
- Secrets are managed using **environment variables**
- `.env` files are excluded using `.gitignore`
- Deployment secrets are stored using platform secret managers
- Clean separation between UI, retrieval, and generation logic

---

## ğŸ“‚ Project Structure

rag-pdf-app/
â”‚
â”œâ”€â”€ app.py                # Streamlit application
â”œâ”€â”€ requirements.txt      # Python dependencies
â”œâ”€â”€ README.md             # Project documentation
â”œâ”€â”€ .gitignore            # Ignore secrets & cache files
â”‚
â”œâ”€â”€ rag/
â”‚   â”œâ”€â”€ loader.py         # PDF loading with page metadata
â”‚   â”œâ”€â”€ chunker.py        # Sentence-based text chunking
â”‚   â”œâ”€â”€ vectorstore.py    # Vector storage & retrieval logic
â”‚   â””â”€â”€ qa.py             # Answer generation using LLM



---

## ğŸ§ª Example Use Cases

- Studying from textbooks and research papers
- Quickly finding information in large PDFs
- Verifying answers with exact page references
- Understanding and summarizing technical documents

---

## ğŸ¯ Why This Project Matters

Unlike generic AI chatbots, this assistant:

- Does **not hallucinate**
- Produces **verifiable answers**
- Clearly shows **where each answer comes from**
- Emphasizes **explainable and trustworthy AI**

This project demonstrates a **real-world RAG system** with production-oriented design,
not a prompt-only chatbot or tutorial example.

---

## ğŸ“Œ Future Enhancements

- Inline citations within generated answers
- Export chat history as PDF
- Support for multiple PDFs
- Highlighting answer sentences in source text
- Deployment on Streamlit Cloud or Hugging Face Spaces

---

## ğŸ§  Author Notes

This project was built with a focus on **clean architecture, robustness, and user trust**.
It reflects production-level thinking and practical application of
Retrieval-Augmented Generation systems.

---

â­ If you find this project useful, consider starring the repository!
